"""
æ‹¼å¤šå¤šä¸ªäººè®¢å•çˆ¬å–å·¥å…· v4.3
æ–°å¢åŠŸèƒ½ï¼š
1. å¢åŠ å‘½ä»¤è¡Œå‚æ•°-d/--daysï¼Œæ§åˆ¶æ˜¾ç¤ºå¤šå°‘å¤©å†…çš„å†å²è®¢å•
2. å®ç°PageDownæ»šåŠ¨åŠ è½½æ›´å¤šå†å²è®¢å•
3. æ ¹æ®è®¢å•å·å‰6ä½åˆ¤æ–­æ˜¯å¦ç»§ç»­åŠ è½½
4. æ”¹è¿›ç¿»é¡µé€»è¾‘ï¼šå…ˆPageDownåˆ°åº•éƒ¨ï¼Œç‚¹å‡»æœ€åä¸€ä¸ªè®¢å•æ£€æŸ¥æ—¶é—´
"""

import os
import sys
import json
import time
import random
import re
import argparse
from datetime import datetime, timedelta
from seleniumbase import Driver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from pdd_login import PinduoduoLogin


class PinduoduoOrderScraper:
    def __init__(self, headless=False, days=30):
        self.headless = headless
        self.days = days  # æ§åˆ¶æ˜¾ç¤ºå¤šå°‘å¤©å†…çš„è®¢å•
        self.driver = None
        self.orders = []
        self.is_already_on_orders_page = False
        self.display_mode = "unknown"  # unknown, overview, full_list
        self.login_module = None  # ç™»å½•æ¨¡å—å®ä¾‹

    def start_browser(self):
        print("å¯åŠ¨æµè§ˆå™¨...")
        self.driver = Driver(
            browser="chrome",
            headless=self.headless,
            uc=True,
            incognito=True,
        )
        self.driver.set_page_load_timeout(60)
        self.driver.implicitly_wait(10)

        # â­ Chromeçª—å£è®¾ç½®ä¸º1280x1920 (ç§»åŠ¨ç«¯ä¼˜åŒ–)
        self.driver.set_window_size(1280, 1920)  # å®½åº¦1280ï¼Œé«˜åº¦1920
        # åˆå§‹åŒ–ç™»å½•æ¨¡å—
        self.login_module = PinduoduoLogin(self.driver, ".pdd_cookies.json")
        print(f"æµè§ˆå™¨å¯åŠ¨æˆåŠŸ (1280x1920 ç§»åŠ¨ç«¯ä¼˜åŒ–, è®¢å•èŒƒå›´: {self.days}å¤©å†…)")
        return self

    def smart_wait(self, seconds_range=(2, 4)):
        time.sleep(random.uniform(*seconds_range))

    def random_small_wait(self):
        """éšæœºå°ç­‰å¾…æ—¶é—´ (0.5~1.2ç§’)"""
        time.sleep(random.uniform(0.5, 1.2))

    def parse_order_date_from_sn(self, order_sn):
        """
        ä»è®¢å•å·è§£ææ—¥æœŸ
        è®¢å•å·æ ¼å¼: 260118-307453049133668
        å‰6ä½: YYMMDD (260118 = 2026å¹´01æœˆ18æ—¥)

        Returns:
            datetime: è®¢å•æ—¥æœŸï¼Œå¦‚æœè§£æå¤±è´¥è¿”å›None
        """
        try:
            if not order_sn or len(order_sn) < 6:
                return None

            # æå–å‰6ä½
            date_part = order_sn[:6]

            # è§£ææ—¥æœŸ (YYMMDDæ ¼å¼)
            year = int(date_part[:2])
            month = int(date_part[2:4])
            day = int(date_part[4:6])

            # è½¬æ¢ä¸ºå®Œæ•´å¹´ä»½ (2000 + year)
            full_year = 2000 + year

            # åˆ›å»ºæ—¥æœŸå¯¹è±¡
            order_date = datetime(full_year, month, day)
            return order_date
        except (ValueError, IndexError) as e:
            print(f"âš ï¸ è§£æè®¢å•æ—¥æœŸå¤±è´¥: {order_sn}, é”™è¯¯: {e}")
            return None

    def is_order_within_days(self, order_sn, days=None):
        """
        æ£€æŸ¥è®¢å•æ˜¯å¦åœ¨æŒ‡å®šå¤©æ•°å†…

        Args:
            order_sn: è®¢å•å·
            days: å¤©æ•°ï¼ŒNoneåˆ™ä½¿ç”¨å®ä¾‹çš„dayså±æ€§

        Returns:
            bool: è®¢å•æ˜¯å¦åœ¨æŒ‡å®šå¤©æ•°å†…
        """
        if days is None:
            days = self.days

        order_date = self.parse_order_date_from_sn(order_sn)

        if order_date is None:
            # å¦‚æœæ— æ³•è§£ææ—¥æœŸï¼Œé»˜è®¤åŒ…å«è¯¥è®¢å•
            return True

        # è®¡ç®—æ—¥æœŸå·®
        today = datetime.now()
        days_diff = (today - order_date).days

        return days_diff <= days

    def scroll_page_down_times(self, times=50):
        """
        å‘é€PageDowné”®å¤šæ¬¡

        Args:
            times: æ»šåŠ¨æ¬¡æ•°

        Returns:
            int: æˆåŠŸæ»šåŠ¨çš„æ¬¡æ•°
        """
        print(f"\nğŸ”„ å¼€å§‹PageDownæ»šåŠ¨ ({times}æ¬¡)...")
        successful_scrolls = 0

        for i in range(times):
            try:
                # å‘é€PageDowné”®
                body = self.driver.find_element(By.TAG_NAME, "body")
                body.send_keys(Keys.PAGE_DOWN)

                # éšæœºç­‰å¾… 0.5~1.2ç§’
                self.random_small_wait()

                successful_scrolls += 1

                # æ¯10æ¬¡æ˜¾ç¤ºè¿›åº¦
                if (i + 1) % 10 == 0:
                    print(f"  ğŸ“œ å®Œæˆ {i + 1}/{times} æ¬¡PageDown...")

            except Exception as e:
                print(f"  âš ï¸ ç¬¬{i + 1}æ¬¡PageDownå¤±è´¥: {e}")
                continue

        print(f"âœ… PageDownæ»šåŠ¨å®Œæˆï¼ŒæˆåŠŸ {successful_scrolls}/{times} æ¬¡")
        return successful_scrolls

    def get_all_order_links(self):
        """
        è·å–é¡µé¢ä¸Šæ‰€æœ‰è®¢å•çš„é“¾æ¥

        æ”¯æŒæ‹¼å¤šå¤šReact SPAå’Œä¼ ç»ŸHTMLä¸¤ç§é¡µé¢ç±»å‹ï¼š
        1. ä¼˜å…ˆä»window.rawData.ordersæå–ï¼ˆReact SPAï¼‰
        2. å›é€€åˆ°DOMå…ƒç´ æå–ï¼ˆä¼ ç»ŸHTMLï¼‰

        Returns:
            list: è®¢å•é“¾æ¥å…ƒç´ åˆ—è¡¨ï¼ˆMockElementæˆ–çœŸå®DOMå…ƒç´ ï¼‰
        """
        try:
            # æ–¹æ³•1: ä¼˜å…ˆä½¿ç”¨ JavaScript æå–
            print("ğŸ” å°è¯•ä» window.rawData æå–è®¢å•é“¾æ¥...")
            orders_data = self.extract_orders_from_raw_data()

            if orders_data:
                print(f"  âœ… ä½¿ç”¨ JavaScript æå–åˆ° {len(orders_data)} ä¸ªè®¢å•")

                # åˆ›å»ºæ¨¡æ‹Ÿå…ƒç´ å¯¹è±¡ä»¥å…¼å®¹ç°æœ‰ä»£ç 
                mock_elements = []
                for order in orders_data:

                    class MockElement:
                        def __init__(self, order_sn, order_link):
                            self.order_sn = order_sn
                            self.order_link = order_link

                        def get_attribute(self, attr):
                            if attr == "href":
                                return self.order_link
                            return None

                    mock_elements.append(
                        MockElement(order["order_sn"], order["order_link"])
                    )

                return mock_elements

            # æ–¹æ³•2: å›é€€åˆ° DOM æå–
            print("  âš ï¸ JavaScript æå–å¤±è´¥ï¼Œå°è¯• DOM æå–...")
            order_links = self.driver.find_elements(
                By.XPATH,
                "//a[contains(@href, 'order.html') or contains(@href, 'order_sn')]",
            )

            if order_links:
                print(f"  âœ… ä½¿ç”¨ DOM æå–åˆ° {len(order_links)} ä¸ªè®¢å•é“¾æ¥")
            else:
                print("  âŒ DOM æå–ä¹Ÿæœªèƒ½æ‰¾åˆ°è®¢å•é“¾æ¥")

            return order_links

        except Exception as e:
            print(f"  âŒ è·å–è®¢å•é“¾æ¥å¤±è´¥: {e}")
            return []

    def click_last_order_and_check_date(self):
        """
        ç‚¹å‡»æœ€åä¸€ä¸ªè®¢å•ï¼Œæ£€æŸ¥æ—¶é—´æ˜¯å¦æ»¡è¶³è¦æ±‚

        Returns:
            tuple: (æ˜¯å¦æ»¡è¶³æ—¶é—´è¦æ±‚, è®¢å•å·, è®¢å•æ—¥æœŸ)
        """
        try:
            # è·å–æ‰€æœ‰è®¢å•é“¾æ¥
            order_links = self.get_all_order_links()

            if not order_links:
                print("  âŒ é¡µé¢ä¸Šæ²¡æœ‰æ‰¾åˆ°è®¢å•é“¾æ¥")
                return False, None, None

            print(f"  ğŸ“¦ é¡µé¢ä¸Šæœ‰ {len(order_links)} ä¸ªè®¢å•")

            # è·å–æœ€åä¸€ä¸ªè®¢å•é“¾æ¥
            last_order = order_links[-1]

            # å°è¯•è·å–è®¢å•å· - å…¼å®¹ä¸¤ç§å…ƒç´ ç±»å‹
            order_sn = None

            # æ£€æŸ¥æ˜¯å¦ä¸º MockElement (æ¥è‡ª JavaScript æå–)
            if hasattr(last_order, "order_sn"):
                print("  ğŸ“‹ å¤„ç† MockElement (JavaScript æå–)")
                order_sn = last_order.order_sn
            else:
                print("  ğŸ“‹ å¤„ç† DOM å…ƒç´  (ä¼ ç»Ÿæå–)")
                # ä¼ ç»Ÿ DOM å…ƒç´ å¤„ç†
                href = last_order.get_attribute("href") or ""
                order_sn = self.extract_order_sn_from_url(href)

                if not order_sn:
                    # å°è¯•ä»é“¾æ¥æ–‡æœ¬æˆ–å…¶ä»–å±æ€§æå–
                    order_sn = self.extract_order_sn_from_page()

            # è·å–è®¢å•æ—¥æœŸ
            order_date = self.parse_order_date_from_sn(order_sn)

            if order_sn and order_date:
                is_within = self.is_order_within_days(order_sn)

                print(f"  ğŸ¯ æ£€æŸ¥æœ€åä¸€ä¸ªè®¢å•:")
                print(f"     è®¢å•å·: {order_sn}")
                print(f"     è®¢å•æ—¥æœŸ: {order_date.strftime('%Y-%m-%d')}")
                print(
                    f"     æ˜¯å¦åœ¨{self.days}å¤©å†…: {'âœ… æ˜¯' if is_within else 'âŒ å¦'}"
                )

                return is_within, order_sn, order_date
            else:
                print(f"  âŒ æ— æ³•è·å–è®¢å•ä¿¡æ¯")
                return False, None, None

        except Exception as e:
            print(f"  âš ï¸ æ£€æŸ¥æœ€åä¸€ä¸ªè®¢å•å¤±è´¥: {e}")
            return False, None, None

    def extract_order_sn_from_url(self, url):
        """
        ä»URLä¸­æå–è®¢å•å·

        Args:
            url: è®¢å•è¯¦æƒ…é¡µURL

        Returns:
            str: è®¢å•å·
        """
        try:
            if not url:
                return None

            # å°è¯•åŒ¹é…è®¢å•å·æ ¼å¼
            patterns = [
                r'order[_-]?sn[=:]?\s*["\']?(\d{6}-\d{12,})',
                r"order\.html\?.*order[_-]?sn[=:]?(\d{6}-\d{12,})",
                r"(\d{6}-\d{12,})",
            ]

            for pattern in patterns:
                match = re.search(pattern, url, re.IGNORECASE)
                if match:
                    order_sn = (
                        match.group(1)
                        if match.lastindex == 0
                        else match.group(match.lastindex)
                    )
                    if order_sn and len(order_sn) > 10:
                        return order_sn

            return None
        except:
            return None

    def extract_order_sn_from_page(self):
        """
        ä»é¡µé¢æå–ä¸€ä¸ªè®¢å•å·

        Returns:
            str: è®¢å•å·
        """
        try:
            page_text = self.driver.page_source

            patterns = [
                r"(\d{6}-\d{12,})",  # 260118-307453049133668
                r'order[_-]?sn["\']?\s*[:=]\s*["\']?(\d{6}-\d{12,})',
            ]

            for pattern in patterns:
                match = re.search(pattern, page_text, re.IGNORECASE)
                if match:
                    order_sn = (
                        match.group(1)
                        if match.lastindex == 0
                        else match.group(match.lastindex)
                    )
                    if order_sn and len(order_sn) > 10:
                        return order_sn

            return None
        except:
            return None

    def extract_orders_from_raw_data(self):
        """
        ä»window.rawDataæå–è®¢å•æ•°æ®ï¼ˆReact SPAé¡µé¢ä¸“ç”¨ï¼‰

        æ‹¼å¤šå¤šæ–°é¡µé¢ä½¿ç”¨Reactå•é¡µåº”ç”¨ï¼Œè®¢å•æ•°æ®å­˜å‚¨åœ¨JavaScriptå¯¹è±¡ä¸­
        è€Œéä¼ ç»ŸHTMLçš„DOMç»“æ„ã€‚

        Returns:
            list: è®¢å•æ•°æ®åˆ—è¡¨ï¼ŒåŒ…å«order_sn, order_link, order_amountç­‰å­—æ®µ
            è¿”å›ç©ºåˆ—è¡¨å¦‚æœwindow.rawDataä¸å­˜åœ¨æˆ–æ²¡æœ‰è®¢å•æ•°æ®
        """
        """
        ä» window.rawData JavaScript å¯¹è±¡æå–è®¢å•æ•°æ®

        Returns:
            list: è®¢å•å­—å…¸åˆ—è¡¨ï¼ŒåŒ…å« order_sn, order_link, order_amount, status
        """
        try:
            print("ğŸ” å°è¯•ä» window.rawData æå–è®¢å•æ•°æ®...")

            # æ‰§è¡Œ JavaScript è·å–è®¢å•æ•°æ®
            orders_data = self.driver.execute_script("return window.rawData.orders;")

            if not orders_data:
                print("  âŒ window.rawData.orders ä¸ºç©ºæˆ–ä¸å­˜åœ¨")
                return []

            print(f"  âœ… ä» window.rawData æ‰¾åˆ° {len(orders_data)} ä¸ªè®¢å•")

            extracted_orders = []
            for order in orders_data:
                try:
                    order_sn = order.get("orderSn", "")
                    order_link = order.get("orderLinkUrl", "")
                    order_amount = order.get("orderAmount", "0")
                    status = order.get("status", 0)

                    if order_sn:
                        extracted_orders.append(
                            {
                                "order_sn": order_sn,
                                "order_link": order_link,
                                "order_amount": order_amount,
                                "status": status,
                                "goods": order.get("orderGoods", []),
                            }
                        )
                except Exception as e:
                    print(f"  âš ï¸ å¤„ç†è®¢å•æ•°æ®æ—¶å‡ºé”™: {e}")
                    continue

            print(f"  âœ… æˆåŠŸæå– {len(extracted_orders)} ä¸ªè®¢å•")
            return extracted_orders

        except Exception as e:
            print(f"  âŒ ä» window.rawData æå–è®¢å•å¤±è´¥: {e}")
            return []

    def check_loading_indicator(self):
        """
        æ£€æŸ¥æ˜¯å¦æœ‰åŠ è½½ä¸­çš„æŒ‡ç¤ºå™¨

        Returns:
            bool: æ˜¯å¦æœ‰åŠ è½½æ´»åŠ¨
        """
        try:
            # æŸ¥æ‰¾åŠ è½½æç¤º
            loading_texts = ["åŠ è½½ä¸­", "æ­£åœ¨åŠ è½½", "loading", "åŠ è½½æ›´å¤š"]

            for text in loading_texts:
                elements = self.driver.find_elements(
                    By.XPATH, f"//*[contains(text(), '{text}')]"
                )
                if elements:
                    for elem in elements:
                        if elem.is_displayed():
                            return True

            # æŸ¥æ‰¾åŠ è½½åŠ¨ç”»
            loading_elements = self.driver.find_elements(
                By.CSS_SELECTOR, ".loading, [class*='loading'], .spinner"
            )
            for elem in loading_elements:
                if elem.is_displayed():
                    return True

            return False
        except:
            return False

    def smart_scroll_to_load_orders(self, initial_scrolls=50, max_scrolls=100):
        """
        æ™ºèƒ½æ»šåŠ¨åŠ è½½è®¢å•ï¼Œç›´åˆ°æ‰¾åˆ°ç¬¦åˆæ—¶é—´è¦æ±‚çš„è®¢å•

        å·¥ä½œæµç¨‹:
        1. å…ˆPageDown 50æ¬¡
        2. ç‚¹å‡»æœ€åä¸€ä¸ªè®¢å•æ£€æŸ¥æ—¶é—´
        3. å¦‚æœä¸æ»¡è¶³ï¼Œç»§ç»­PageDown
        4. é‡å¤ç›´åˆ°æ»¡è¶³æˆ–è¾¾åˆ°æœ€å¤§æ¬¡æ•°

        Args:
            initial_scrolls: åˆå§‹PageDownæ¬¡æ•°
            max_scrolls: æœ€å¤§æ€»æ»šåŠ¨æ¬¡æ•°

        Returns:
            bool: æ˜¯å¦æˆåŠŸæ‰¾åˆ°ç¬¦åˆè¦æ±‚çš„è®¢å•
        """
        print(f"\nğŸ“¦ å¼€å§‹æ™ºèƒ½åŠ è½½è®¢å• (èŒƒå›´: {self.days}å¤©å†…)...")
        print(f"   åˆå§‹æ»šåŠ¨: {initial_scrolls}æ¬¡, æœ€å¤§æ»šåŠ¨: {max_scrolls}æ¬¡")

        total_scrolls = 0
        check_count = 0

        while total_scrolls < max_scrolls:
            check_count += 1
            print(f"\n{'=' * 60}")
            print(f"ğŸ” ç¬¬{check_count}è½®æ£€æŸ¥")
            print(f"{'=' * 60}")

            # 1. å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡ï¼Œå…ˆPageDown 50æ¬¡
            if total_scrolls == 0:
                scrolls_this_round = initial_scrolls
            else:
                scrolls_this_round = 10  # åç»­æ¯æ¬¡10æ¬¡

            # æ»šåŠ¨
            if scrolls_this_round > 0:
                scrolls_done = self.scroll_page_down_times(scrolls_this_round)
                total_scrolls += scrolls_done

                if scrolls_done == 0:
                    print("  âš ï¸ æ— æ³•æ»šåŠ¨ï¼Œå¯èƒ½å·²ç»åˆ°åº•éƒ¨")
                    break

            # 2. ç‚¹å‡»æœ€åä¸€ä¸ªè®¢å•æ£€æŸ¥æ—¶é—´
            print(f"\nğŸ“‹ æ£€æŸ¥å½“å‰é¡µé¢æœ€åä¸€ä¸ªè®¢å•...")
            is_within_days, order_sn, order_date = (
                self.click_last_order_and_check_date()
            )

            if order_sn is None:
                print("  âŒ æ— æ³•è·å–è®¢å•ä¿¡æ¯ï¼Œåœæ­¢æ£€æŸ¥")
                break

            # 3. åˆ¤æ–­æ˜¯å¦æ»¡è¶³æ—¶é—´è¦æ±‚
            if is_within_days:
                print(f"\nâœ… æˆåŠŸï¼æ‰¾åˆ°çš„è®¢å•åœ¨{self.days}å¤©å†…")
                print(f"   æœ€åæ£€æŸ¥çš„è®¢å•æ—¥æœŸ: {order_date.strftime('%Y-%m-%d')}")
                print(f"   æ€»å…±æ»šåŠ¨æ¬¡æ•°: {total_scrolls}")
                return True
            else:
                # è®¢å•è¶…å‡ºæ—¶é—´èŒƒå›´ï¼Œè¯´æ˜å·²ç»åŠ è½½äº†è¶³å¤Ÿçš„å†å²è®¢å•
                if order_date:
                    print(f"\nğŸ›‘ åœæ­¢æ£€æŸ¥ï¼šè®¢å•è¶…å‡º{self.days}å¤©èŒƒå›´")
                    print(f"   æœ€æ—§è®¢å•æ—¥æœŸ: {order_date.strftime('%Y-%m-%d')}")
                    print(f"   æ€»å…±æ»šåŠ¨æ¬¡æ•°: {total_scrolls}")
                    print(f"   ğŸ’¡ è¯´æ˜ï¼šå·²åŠ è½½å®Œæ‰€æœ‰åœ¨{self.days}å¤©å†…çš„è®¢å•")
                    return True  # è¿”å›Trueï¼Œå› ä¸ºå·²ç»æ‰¾åˆ°äº†æ‰€æœ‰ç¬¦åˆè¦æ±‚çš„è®¢å•
                else:
                    print(f"\nâš ï¸ è®¢å•æ—¥æœŸè§£æå¤±è´¥ï¼Œç»§ç»­æ£€æŸ¥")

            # 4. æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§æ»šåŠ¨æ¬¡æ•°
            if total_scrolls >= max_scrolls:
                print(f"\nğŸ›‘ è¾¾åˆ°æœ€å¤§æ»šåŠ¨æ¬¡æ•° ({max_scrolls})ï¼Œåœæ­¢")
                break

        print(f"\nâŒ æœªèƒ½å®Œæˆè®¢å•æ£€æŸ¥")
        return False

    def detect_display_mode(self, page_text):
        """
        æ£€æµ‹è®¢å•æ˜¾ç¤ºæ¨¡å¼

        Returns:
            str: 'overview', 'full_list', or 'unknown'
        """
        page_text_lower = page_text.lower()

        # â­ æ£€æµ‹æ˜¯å¦ä¸ºå®Œæ•´è®¢å•åˆ—è¡¨æ¨¡å¼
        # ç‰¹å¾ï¼šæœ‰å…·ä½“è®¢å•é¡¹ï¼ˆå•†å“ã€é‡‘é¢ã€çŠ¶æ€ç­‰ï¼‰
        full_list_indicators = [
            # æ£€æŸ¥æ˜¯å¦æœ‰è®¢å•ç›¸å…³å…ƒç´ 
            "order-item" in page_text_lower,
            "goods-item" in page_text_lower,
            "list-item" in page_text_lower,
            # æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªè®¢å•çŠ¶æ€
            page_text_lower.count("å¾…ä»˜æ¬¾")
            + page_text_lower.count("å¾…å‘è´§")
            + page_text_lower.count("å¾…æ”¶è´§")
            >= 3,
            # æ£€æŸ¥æ˜¯å¦æœ‰ä»·æ ¼ä¿¡æ¯
            page_text_lower.count("Â¥") >= 5,
            # æ£€æŸ¥æ˜¯å¦æœ‰è®¢å•å·
            bool(re.search(r"\d{10,20}", page_text)),
            # æ£€æŸ¥æ˜¯å¦æœ‰å•†å“ä¿¡æ¯
            any(
                keyword in page_text_lower
                for keyword in ["å•†å“", "è´­ä¹°", "è´­ä¹°è®°å½•", "è®¢å•è¯¦æƒ…"]
            ),
        ]

        if sum(full_list_indicators) >= 3:
            return "full_list"

        # â­ æ£€æµ‹æ˜¯å¦ä¸ºè®¢å•æ¦‚è§ˆæ¨¡å¼
        overview_indicators = [
            # åŸºæœ¬ç»“æ„æ£€æµ‹
            'class="order-menu"' in page_text,
            'class="order-title"' in page_text,
            'class="top-menu-wrapper"' in page_text,
            'class="top-menu"' in page_text,
            # å…³é”®å…ƒç´ æ£€æµ‹
            "æˆ‘çš„è®¢å•" in page_text,
            "æŸ¥çœ‹å…¨éƒ¨" in page_text,
            # çŠ¶æ€ç»Ÿè®¡
            "å¾…ä»˜æ¬¾" in page_text,
            "å¾…å‘è´§" in page_text,
            "å¾…æ”¶è´§" in page_text,
            # æ•°å­—æ ‡ç­¾
            "long-number-tag" in page_text,
        ]

        if sum(overview_indicators) >= 4:
            return "overview"

        return "unknown"

    def click_personal_center_exact(self):
        """ç²¾ç¡®ç‚¹å‡»ä¸ªäººä¸­å¿ƒ"""
        print("æŸ¥æ‰¾ä¸ªäººä¸­å¿ƒ...")
        try:
            footer_items = self.driver.find_elements(By.CSS_SELECTOR, "div.footer-item")
            print(f"æ‰¾åˆ° {len(footer_items)} ä¸ª footer-item å…ƒç´ ")
            for i, item in enumerate(footer_items):
                try:
                    text_elem = item.find_element(
                        By.CSS_SELECTOR, "div.footer-item-text"
                    )
                    text = text_elem.text
                    print(f"  ç¬¬{i + 1}ä¸ª: {text}")
                    if "ä¸ªäººä¸­å¿ƒ" in text:
                        print(f"âœ… æ‰¾åˆ°ä¸ªäººä¸­å¿ƒï¼ˆç¬¬{i + 1}ä¸ªï¼‰")
                        self.driver.execute_script("arguments[0].click();", item)
                        self.smart_wait((2, 3))
                        return True
                except:
                    continue
        except Exception as e:
            print(f"æ–¹æ³•å¤±è´¥: {e}")
        print("\næç¤ºï¼šè¯·æ‰‹åŠ¨ç‚¹å‡»åº•éƒ¨çš„ä¸ªäººä¸­å¿ƒå›¾æ ‡ï¼Œç„¶åæŒ‰å›è½¦ç»§ç»­...")
        input()
        return True

    def login_sms(self, phone):
        print(f"ä½¿ç”¨çŸ­ä¿¡ç™»å½•: {phone[:3]}****{phone[-4:]}")
        print("æŸ¥æ‰¾çŸ­ä¿¡ç™»å½•é€‰é¡¹...")
        sms_selectors = [
            "//*[contains(text(), 'çŸ­ä¿¡ç™»å½•')]",
            "//*[contains(text(), 'éªŒè¯ç ç™»å½•')]",
        ]
        for selector in sms_selectors:
            try:
                elements = self.driver.find_elements(By.XPATH, selector)
                for elem in elements:
                    if elem.is_displayed():
                        print(f"âœ… æ‰¾åˆ°çŸ­ä¿¡ç™»å½•é€‰é¡¹")
                        self.driver.execute_script("arguments[0].click();", elem)
                        self.smart_wait((2, 4))
                        break
                else:
                    continue
                break
            except:
                continue
        print("è¾“å…¥æ‰‹æœºå·...")
        phone_input = self.safe_find("//input[@type='tel']")
        if not phone_input:
            phone_input = self.safe_find("//input[contains(@placeholder, 'æ‰‹æœº')]")
        if phone_input:
            phone_input.clear()
            for digit in phone:
                phone_input.send_keys(digit)
                time.sleep(random.uniform(0.2, 0.5))
        else:
            print("âŒ æœªæ‰¾åˆ°æ‰‹æœºå·è¾“å…¥æ¡†")
            return False
        print("è¯·æ±‚éªŒè¯ç ...")
        code_btn = self.safe_find("//button[contains(text(), 'è·å–éªŒè¯ç ')]")
        if code_btn and code_btn.is_enabled():
            self.driver.execute_script("arguments[0].click();", code_btn)
            print("éªŒè¯ç å·²å‘é€ï¼Œè¯·æŸ¥æ”¶çŸ­ä¿¡...")
            self.smart_wait((5, 10))
            code = input("è¯·è¾“å…¥æ”¶åˆ°çš„éªŒè¯ç ï¼ˆ6ä½æ•°å­—ï¼‰: ").strip()
            print("è¾“å…¥éªŒè¯ç ...")
            code_input = self.safe_find(
                "//input[@type='tel' and contains(@placeholder, 'éªŒè¯ç ')]"
            )
            if not code_input:
                all_inputs = self.driver.find_elements(By.XPATH, "//input[@type='tel']")
                if len(all_inputs) >= 2:
                    code_input = all_inputs[1]
            if code_input:
                code_input.clear()
                for digit in code:
                    code_input.send_keys(digit)
                    time.sleep(random.uniform(0.3, 0.6))
                print("æäº¤ç™»å½•...")
                submit_btn = self.safe_find("//button[contains(text(), 'ç™»å½•')]")
                if submit_btn:
                    self.driver.execute_script("arguments[0].click();", submit_btn)
                    print("ç­‰å¾…ç™»å½•éªŒè¯...")
                    time.sleep(5)
                    print("âœ… ç™»å½•å®Œæˆï¼Œç­‰å¾…åç»­åˆ†æ...")
                    time.sleep(2)
                    return True
        return False

    def login_qr(self):
        print("ä½¿ç”¨æ‰«ç ç™»å½•...")
        print("æŸ¥æ‰¾æ‰«ç ç™»å½•é€‰é¡¹...")
        qr_selectors = [
            "//*[contains(text(), 'æ‰«ç ç™»å½•')]",
            "//*[contains(text(), 'äºŒç»´ç ç™»å½•')]",
        ]
        for selector in qr_selectors:
            try:
                elements = self.driver.find_elements(By.XPATH, selector)
                for elem in elements:
                    if elem.is_displayed():
                        self.driver.execute_script("arguments[0].click();", elem)
                        print("âœ… æ‰¾åˆ°æ‰«ç ç™»å½•é€‰é¡¹")
                        break
            except:
                continue
        self.smart_wait((3, 5))
        print("ç­‰å¾…äºŒç»´ç åŠ è½½...")
        time.sleep(8)
        print("\n" + "=" * 50)
        print("è¯·ä½¿ç”¨æ‹¼å¤šå¤šAPPæ‰«æå±å¹•ä¸Šçš„äºŒç»´ç ")
        print("=" * 50 + "\n")
        input("APPç¡®è®¤ç™»å½•åï¼ŒæŒ‰å›è½¦ç»§ç»­...")
        print("âœ… æ‰«ç ç™»å½•å®Œæˆï¼Œç­‰å¾…åç»­åˆ†æ...")
        time.sleep(2)
        return True

    def safe_find(self, xpath, timeout=15):
        try:
            return WebDriverWait(self.driver, timeout).until(
                EC.presence_of_element_located((By.XPATH, xpath))
            )
        except:
            return None

    def check_login_status_fast(self):
        """å¿«é€Ÿæ£€æµ‹ç™»å½•çŠ¶æ€"""
        print("å¿«é€Ÿæ£€æµ‹ç™»å½•çŠ¶æ€...")
        for i in range(2):  # åªæ£€æŸ¥2æ¬¡
            time.sleep(2)
            page_text = self.driver.page_source
            current_url = self.driver.current_url
            if "éªŒè¯ç " in page_text and "æ»‘åŠ¨" in page_text:
                print("âš ï¸ éœ€è¦æ»‘åŠ¨éªŒè¯ç ...")
                input("è¯·åœ¨æµè§ˆå™¨ä¸­å®ŒæˆéªŒè¯ï¼ŒæŒ‰å›è½¦ç»§ç»­...")
                continue
            # æ£€æµ‹ç™»å½•æˆåŠŸ
            if self.is_logged_in_success_fast(page_text, current_url):
                print("âœ… ç™»å½•æˆåŠŸï¼")
                return True
            print(f"â³ ç­‰å¾…ç™»å½•ä¸­... ({i + 1}/2)")
        return False

    def is_logged_in_success_fast(self, page_text, current_url):
        """å¿«é€Ÿæ£€æµ‹ç™»å½•æˆåŠŸ - ä¼˜åŒ–ç‰ˆ"""
        page_text_lower = page_text.lower()
        current_url_lower = current_url.lower()

        if "login" in current_url_lower:
            return False

        # â­ æ£€æµ‹æ˜¾ç¤ºæ¨¡å¼
        self.display_mode = self.detect_display_mode(page_text)

        # ä¼˜å…ˆæ£€æµ‹ç”¨æˆ·æä¾›çš„HTMLç»“æ„ï¼ˆæœ€å¿«ï¼‰
        if 'class="order-menu"' in page_text and 'class="order-title"' in page_text:
            print(f"   âœ“ æ£€æµ‹åˆ°è®¢å•èœå•ç»“æ„")
            order_indicators = [
                'class="my-orders"',
                'class="others"',
                'class="top-menu-wrapper"',
                'class="top-menu"',
            ]
            found = [ind for ind in order_indicators if ind in page_text]
            if len(found) >= 3:
                print(f"   âœ“ è®¢å•ç»“æ„åŒ¹é…: {', '.join(found[:3])}")
                # ğŸ¯ åŸºäºä½ æä¾›çš„ç²¾ç¡®HTMLç»“æ„æ£€æµ‹ç™»å½•æˆåŠŸ
            if '<div class="order-menu"><div class="order-title">' in page_text:
                print("   âœ“ æ£€æµ‹åˆ°å®Œæ•´çš„è®¢å•èœå•ç»“æ„")

                # ç²¾ç¡®åŒ¹é…ä½ æä¾›çš„HTMLç»“æ„
                required_structure = [
                    '<div class="my-orders">æˆ‘çš„è®¢å•</div>',
                    '<div class="others">æŸ¥çœ‹å…¨éƒ¨</div>',
                    '<div class="top-menu-wrapper"',
                    '<div class="top-menu"',
                    "å¾…ä»˜æ¬¾",
                    "å¾…åˆ†äº«",
                    "å¾…å‘è´§",
                    "å¾…æ”¶è´§",
                    "è¯„ä»·",
                ]

                found_count = sum(1 for elem in required_structure if elem in page_text)
                match_rate = found_count / len(required_structure)
                print(
                    f"   âœ“ ç»“æ„åŒ¹é…åº¦: {found_count}/{len(required_structure)} ({match_rate * 100:.0f}%)"
                )

                if match_rate >= 0.8:  # 80%ä»¥ä¸ŠåŒ¹é…åº¦
                    print("   âœ“ ğŸ¯ ç¡®è®¤ç™»å½•æˆåŠŸï¼è¿™æ˜¯åŒ…å«è®¢å•ä¿¡æ¯çš„é¡µé¢")
                    print("   âœ“ æ£€æµ‹åˆ°è®¢å•çŠ¶æ€å’Œ'æŸ¥çœ‹å…¨éƒ¨'æŒ‰é’®")
                    self.display_mode = "orders_overview"
                    self.is_already_on_orders_page = True
                    return True
                else:
                    print(f"   âš ï¸ ç»“æ„åŒ¹é…åº¦ä¸è¶³: {match_rate * 100:.0f}%")

            return True

        # æ£€æµ‹å…³é”®æ–‡å­—
        key_indicators = [
            "æˆ‘çš„è®¢å•",
            "æŸ¥çœ‹å…¨éƒ¨",
            "å¾…ä»˜æ¬¾",
            "å¾…å‘è´§",
            "å¾…æ”¶è´§",
            "è¯„ä»·",
            "å¾…åˆ†äº«",
            "order-menu",
            "order-title",
            "top-menu-wrapper",
            "top-menu",
        ]
        found = [ind for ind in key_indicators if ind in page_text]
        if len(found) >= 5:
            print(f"   âœ“ å…³é”®è¯åŒ¹é…: {', '.join(found[:5])}")
            print(f"   âœ“ æ£€æµ‹åˆ°æ˜¾ç¤ºæ¨¡å¼: {self.display_mode}")
            return True

        # æ£€æµ‹å…¶ä»–ç™»å½•æˆåŠŸæ ‡å¿—
        success_indicators = [
            "æˆ‘çš„æ‹¼å¤šå¤š",
            "ä¸ªäººä¸­å¿ƒ",
            "è®¢å•ç®¡ç†",
            "é€€å‡ºç™»å½•",
            "æˆ‘çš„é’±åŒ…",
            "æˆ‘çš„ä¼˜æƒ åˆ¸",
        ]
        for indicator in success_indicators:
            if indicator in page_text:
                print(f"   âœ“ æ£€æµ‹åˆ°ç™»å½•æ ‡å¿—: {indicator}")
                return True

        return False

    def click_view_all_orders_by_mode(self):
        """
        æ ¹æ®æ˜¾ç¤ºæ¨¡å¼ç‚¹å‡»æŸ¥çœ‹å…¨éƒ¨
        """
        print(f"æ£€æµ‹åˆ°è®¢å•æ˜¾ç¤ºæ¨¡å¼: {self.display_mode}")

        if self.display_mode == "overview":
            print("âœ… è®¢å•æ¦‚è§ˆæ¨¡å¼ - ç‚¹å‡»'æŸ¥çœ‹å…¨éƒ¨'è¿›å…¥å®Œæ•´åˆ—è¡¨")
            return self.click_view_all_orders_overview()
        elif self.display_mode == "full_list":
            print("âœ… å®Œæ•´è®¢å•åˆ—è¡¨æ¨¡å¼ - æ— éœ€ç‚¹å‡»ï¼Œç›´æ¥å¼€å§‹çˆ¬å–")
            return True
        else:
            print("âš ï¸ æœªæ£€æµ‹åˆ°è®¢å•é¡µé¢")
            return False

    def click_view_all_orders_overview(self):
        """æ¦‚è§ˆæ¨¡å¼ä¸‹ç‚¹å‡»æŸ¥çœ‹å…¨éƒ¨"""
        print("åœ¨æ¦‚è§ˆæ¨¡å¼ï¼Œç‚¹å‡»æŸ¥çœ‹å…¨éƒ¨...")
        try:
            # æ–¹æ³•1: é€šè¿‡CSSé€‰æ‹©å™¨ç›´æ¥å®šä½
            view_all_elements = self.driver.find_elements(By.CSS_SELECTOR, "div.others")
            print(f"æ‰¾åˆ° {len(view_all_elements)} ä¸ª div.others å…ƒç´ ")
            for i, elem in enumerate(view_all_elements):
                try:
                    text = elem.text.strip()
                    print(f"  ç¬¬{i + 1}ä¸ª: '{text}'")
                    if "æŸ¥çœ‹å…¨éƒ¨" in text:
                        print(f"âœ… æ‰¾åˆ°æŸ¥çœ‹å…¨éƒ¨ï¼ˆç¬¬{i + 1}ä¸ªï¼‰")
                        self.driver.execute_script(
                            "arguments[0].scrollIntoView(true);", elem
                        )
                        time.sleep(1)
                        self.driver.execute_script("arguments[0].click();", elem)
                        self.smart_wait((3, 5))
                        print("âœ… å·²ç‚¹å‡»æŸ¥çœ‹å…¨éƒ¨ï¼Œç­‰å¾…è·³è½¬...")
                        time.sleep(5)  # ç­‰å¾…é¡µé¢è·³è½¬
                        return True
                except:
                    continue
        except Exception as e:
            print(f"æ–¹æ³•1å¤±è´¥: {e}")

        # æ–¹æ³•2: å¤‡ç”¨XPATHæŸ¥æ‰¾
        try:
            text_elements = self.driver.find_elements(
                By.XPATH, "//*[contains(text(), 'æŸ¥çœ‹å…¨éƒ¨')]"
            )
            print(f"æ‰¾åˆ° {len(text_elements)} ä¸ªåŒ…å«'æŸ¥çœ‹å…¨éƒ¨'çš„å…ƒç´ ")
            for i, elem in enumerate(text_elements):
                try:
                    print(f"  ç¬¬{i + 1}ä¸ªå…ƒç´ ï¼Œç‚¹å‡»...")
                    self.driver.execute_script(
                        "arguments[0].scrollIntoView(true);", elem
                    )
                    time.sleep(1)
                    self.driver.execute_script("arguments[0].click();", elem)
                    print("âœ… é€šè¿‡XPATHæ‰¾åˆ°æŸ¥çœ‹å…¨éƒ¨")
                    self.smart_wait((3, 5))
                    return True
                except:
                    continue
        except Exception as e:
            print(f"æ–¹æ³•2å¤±è´¥: {e}")

        print("âŒ æœªæ‰¾åˆ°æŸ¥çœ‹å…¨éƒ¨æŒ‰é’®")
        return False

    def click_view_all_orders(self):
        """ç‚¹å‡»æŸ¥çœ‹å…¨éƒ¨æŒ‰é’® - é€šç”¨ç‰ˆ"""
        print("æŸ¥æ‰¾æŸ¥çœ‹å…¨éƒ¨æŒ‰é’®...")

        # æ–¹æ³•1: é€šè¿‡CSSé€‰æ‹©å™¨ç›´æ¥å®šä½
        try:
            view_all_elements = self.driver.find_elements(By.CSS_SELECTOR, "div.others")
            print(f"æ‰¾åˆ° {len(view_all_elements)} ä¸ª div.others å…ƒç´ ")
            for i, elem in enumerate(view_all_elements):
                try:
                    text = elem.text.strip()
                    print(f"  ç¬¬{i + 1}ä¸ª: '{text}'")
                    if "æŸ¥çœ‹å…¨éƒ¨" in text:
                        print(f"âœ… æ‰¾åˆ°æŸ¥çœ‹å…¨éƒ¨ï¼ˆç¬¬{i + 1}ä¸ªï¼‰")
                        self.driver.execute_script(
                            "arguments[0].scrollIntoView(true);", elem
                        )
                        time.sleep(1)
                        self.driver.execute_script("arguments[0].click();", elem)
                        self.smart_wait((3, 5))
                        return True
                except:
                    continue
        except Exception as e:
            print(f"æ–¹æ³•1å¤±è´¥: {e}")

        # æ–¹æ³•2: é€šè¿‡XPATHæŸ¥æ‰¾
        try:
            text_elements = self.driver.find_elements(
                By.XPATH, "//*[contains(text(), 'æŸ¥çœ‹å…¨éƒ¨')]"
            )
            print(f"æ‰¾åˆ° {len(text_elements)} ä¸ªåŒ…å«'æŸ¥çœ‹å…¨éƒ¨'çš„å…ƒç´ ")
            for i, elem in enumerate(text_elements):
                try:
                    print(f"  ç¬¬{i + 1}ä¸ªå…ƒç´ ï¼Œç‚¹å‡»...")
                    self.driver.execute_script(
                        "arguments[0].scrollIntoView(true);", elem
                    )
                    time.sleep(1)
                    self.driver.execute_script("arguments[0].click();", elem)
                    return True
                except:
                    continue
        except Exception as e:
            print(f"æ–¹æ³•2å¤±è´¥: {e}")

        print("âŒ æœªæ‰¾åˆ°æŸ¥çœ‹å…¨éƒ¨æŒ‰é’®")
        return False

    def check_display_mode_and_click(self, page_text):
        """æ£€æµ‹æ˜¾ç¤ºæ¨¡å¼å¹¶ç‚¹å‡»æŸ¥çœ‹å…¨éƒ¨"""
        self.display_mode = self.detect_display_mode(page_text)
        print(f"âœ… æ£€æµ‹åˆ°æ˜¾ç¤ºæ¨¡å¼: {self.display_mode}")

        if self.display_mode == "overview":
            print("è®¢å•æ¦‚è§ˆæ¨¡å¼ - éœ€è¦ç‚¹å‡»'æŸ¥çœ‹å…¨éƒ¨'")
            if self.click_view_all_orders_overview():
                print("âœ… å·²ç‚¹å‡»æŸ¥çœ‹å…¨éƒ¨")
                return True
        elif self.display_mode == "full_list":
            print("å®Œæ•´åˆ—è¡¨æ¨¡å¼ - ç›´æ¥å¼€å§‹çˆ¬å–")
            return True
        else:
            print("âš ï¸ æœªæ£€æµ‹åˆ°æ ‡å‡†è®¢å•é¡µé¢")
            return False

    def login_via_personal_center(self, phone, login_type="sms"):
        """é€šè¿‡ä¸ªäººä¸­å¿ƒå…¥å£ç™»å½• - ä½¿ç”¨ç™»å½•æ¨¡å—"""
        success = self.login_module.login_via_personal_center(phone, login_type)
        if success:
            # åŒæ­¥ç™»å½•çŠ¶æ€åˆ°ä¸»ç±»
            self.is_already_on_orders_page = self.login_module.is_already_on_orders_page
            self.display_mode = self.login_module.display_mode
            print("âœ… ç™»å½•æˆåŠŸ")
        return success

    def navigate_to_orders(self):
        try:
            if self.is_already_on_orders_page:
                print("âœ… å·²åœ¨è®¢å•é¡µé¢ï¼Œä¸è¿›è¡Œè‡ªåŠ¨è·³è½¬...")
                print("ğŸ“‹ å½“å‰é¡µé¢åŒ…å«è®¢å•ä¿¡æ¯ï¼Œå¯ä»¥ç›´æ¥åˆ†æ")
                return True
            print("å‰å¾€è®¢å•é¡µé¢...")
            self.driver.get("https://mobile.pinduoduo.com/orders")
            self.smart_wait((3, 5))
            if "login" in self.driver.current_url.lower():
                print("éœ€è¦ç™»å½•")
                return False
            page_text = self.driver.page_source
            if self.check_display_mode_and_click(page_text):
                return True
            print("âœ… è®¢å•é¡µé¢åŠ è½½å®Œæˆ")
            return True
        except Exception as e:
            print(f"å¯¼èˆªå¤±è´¥: {e}")
            return False

    def search_order_links_on_current_page(self):
        """åœ¨å½“å‰é¡µé¢æœç´¢æ‰€æœ‰è®¢å•ç›¸å…³çš„è·³è½¬é“¾æ¥"""
        print("\nåœ¨å½“å‰é¡µé¢æœç´¢è®¢å•è·³è½¬é“¾æ¥...")

        page_source = self.driver.page_source
        current_url = self.driver.current_url
        print(f"å½“å‰é¡µé¢: {current_url}")

        # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„è®¢å•ç›¸å…³é“¾æ¥
        import re

        # ç®€å•çš„é“¾æ¥æœç´¢
        order_link_patterns = [
            r'href="([^"]*order[^"]*)',
            r'href="([^"]*orders[^"]*)',
            r'data-href="([^"]*order[^"]*)',
        ]

        found_links = set()
        print("\næœç´¢è®¢å•ç›¸å…³é“¾æ¥:")
        for pattern in order_link_patterns:
            try:
                matches = re.findall(pattern, page_source, re.IGNORECASE)
                for match in matches:
                    if match and len(match) > 3:
                        found_links.add(match)
            except:
                continue

        # æŸ¥æ‰¾å¯ç‚¹å‡»çš„è®¢å•ç›¸å…³å…ƒç´ 
        clickable_elements = []
        order_keywords = ["è®¢å•", "æŸ¥çœ‹å…¨éƒ¨", "è¯¦æƒ…", "order", "orders"]

        for keyword in order_keywords:
            try:
                elements = self.driver.find_elements(
                    By.XPATH, f"//*[contains(text(), '{keyword}')]"
                )
                for elem in elements:
                    try:
                        tag_name = elem.tag_name.lower()
                        if tag_name in ["a", "button", "div"]:
                            href = elem.get_attribute("href") or elem.get_attribute(
                                "data-href"
                            )
                            text = elem.text.strip()

                            if text and len(text) > 0:
                                clickable_elements.append(
                                    {
                                        "element": elem,
                                        "text": text,
                                        "tag": tag_name,
                                        "href": href,
                                        "class": elem.get_attribute("class"),
                                    }
                                )
                    except:
                        continue
            except:
                continue

        print(f"\næ‰¾åˆ° {len(found_links)} ä¸ªè®¢å•ç›¸å…³é“¾æ¥:")
        for i, link in enumerate(found_links, 1):
            print(f"  {i}. {link}")

        print(f"\næ‰¾åˆ° {len(clickable_elements)} ä¸ªå¯ç‚¹å‡»çš„è®¢å•å…ƒç´ :")
        for i, elem_info in enumerate(clickable_elements, 1):
            print(f"  {i}. <{elem_info['tag']}> {elem_info['text'][:50]}...")
            if elem_info["href"]:
                print(f"     é“¾æ¥: {elem_info['href'][:100]}...")
            if elem_info["class"]:
                print(f"     ç±»å: {elem_info['class']}")

        # ç‰¹åˆ«å…³æ³¨"æŸ¥çœ‹å…¨éƒ¨"æŒ‰é’®
        view_all_elements = []
        for elem_info in clickable_elements:
            if "æŸ¥çœ‹å…¨éƒ¨" in elem_info["text"]:
                view_all_elements.append(elem_info)

        if view_all_elements:
            print(f"\næ‰¾åˆ° {len(view_all_elements)} ä¸ª'æŸ¥çœ‹å…¨éƒ¨'å…ƒç´ :")
            for i, elem_info in enumerate(view_all_elements, 1):
                print(f"  {i}. ç±»å: {elem_info['class']}, æ–‡æœ¬: '{elem_info['text']}'")

        # ä¿å­˜æœç´¢ç»“æœ
        from datetime import datetime

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        search_result_file = f"order_links_search_{timestamp}.txt"

        try:
            with open(search_result_file, "w", encoding="utf-8") as f:
                f.write(f"è®¢å•é“¾æ¥æœç´¢ç»“æœ\n")
                f.write(f"æ—¶é—´: {datetime.now()}\n")
                f.write(f"å½“å‰é¡µé¢: {current_url}\n\n")

                f.write(f"\n=== æ‰¾åˆ°çš„è®¢å•é“¾æ¥ ({len(found_links)}ä¸ª) ===\n")
                for link in found_links:
                    f.write(f"{link}\n")

                f.write(f"\n=== å¯ç‚¹å‡»çš„è®¢å•å…ƒç´  ({len(clickable_elements)}ä¸ª) ===\n")
                for i, elem_info in enumerate(clickable_elements, 1):
                    f.write(f"{i}. <{elem_info['tag']}> {elem_info['text']}\n")
                    if elem_info["href"]:
                        f.write(f"   é“¾æ¥: {elem_info['href']}\n")
                    if elem_info["class"]:
                        f.write(f"   ç±»å: {elem_info['class']}\n")
                    f.write("\n")

            print(f"\næœç´¢ç»“æœå·²ä¿å­˜: {search_result_file}")
        except Exception as e:
            print(f"\nä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")

        return found_links, clickable_elements

    def detect_page_version_and_fallback(self):
        """
        æ£€æµ‹é¡µé¢ç‰ˆæœ¬å¹¶é€‰æ‹©é€‚å½“çš„æå–æ–¹æ³•

        Returns:
            str: é¡µé¢ç‰ˆæœ¬ç±»å‹ ('react-spa', 'traditional', 'unknown')
        """
        try:
            # æ–¹æ³•1: æ£€æŸ¥æ˜¯å¦æœ‰ window.rawData
            has_raw_data = self.driver.execute_script(
                "return typeof window.rawData !== 'undefined';"
            )

            if has_raw_data:
                print("ğŸ¯ æ£€æµ‹åˆ° React SPA é¡µé¢")
                return "react-spa"

            # æ–¹æ³•2: æ£€æŸ¥ä¼ ç»ŸDOMç»“æ„
            page_source = self.driver.page_source
            traditional_indicators = [
                "//a[contains(@href, 'order.html')]",
                "//a[contains(@href, 'order_sn')]",
                "order-item",
                "goods-item",
            ]

            for indicator in traditional_indicators:
                if self.driver.find_elements(By.XPATH, indicator):
                    print("ğŸ¯ æ£€æµ‹åˆ°ä¼ ç»Ÿ HTML é¡µé¢")
                    return "traditional"

            print("â“ æœªæ£€æµ‹åˆ°æ˜ç¡®çš„é¡µé¢ç»“æ„")
            return "unknown"

        except Exception as e:
            print(f"  âš ï¸ é¡µé¢ç‰ˆæœ¬æ£€æµ‹å¤±è´¥: {e}")
            return "unknown"

    def enhanced_order_extraction_with_fallback(self):
        """
        å¢å¼ºçš„è®¢å•æå–ï¼ŒåŒ…å«å¤šç§å›é€€ç­–ç•¥

        Returns:
            list: è®¢å•åˆ—è¡¨ï¼Œæ”¯æŒå¤šç§æå–æ–¹æ³•
        """
        page_version = self.detect_page_version_and_fallback()

        if page_version == "react-spa":
            print("ğŸ“± ä½¿ç”¨ JavaScript æå–æ–¹æ³•")
            orders_data = self.extract_orders_from_raw_data()

            # è½¬æ¢ä¸ºå…¼å®¹æ ¼å¼
            class MockElement:
                def __init__(self, order_sn, order_link):
                    self.order_sn = order_sn
                    self.order_link = order_link

                def get_attribute(self, attr):
                    if attr == "href":
                        return self.order_link
                    return None

            return [
                MockElement(order["order_sn"], order["order_link"])
                for order in orders_data
            ]

        elif page_version == "traditional":
            print("ğŸ”— ä½¿ç”¨ä¼ ç»Ÿ DOM æå–æ–¹æ³•")
            return self.driver.find_elements(
                By.XPATH,
                "//a[contains(@href, 'order.html') or contains(@href, 'order_sn')]",
            )

        else:
            print("âš ï¸ é¡µé¢ç»“æ„æœªçŸ¥ï¼Œå°è¯•æ‰€æœ‰æ–¹æ³•")
            # å°è¯• JavaScript æå–
            try:
                orders_data = self.extract_orders_from_raw_data()
                if orders_data:
                    print("âœ… JavaScript æå–æˆåŠŸ")
                    return self._create_mock_elements(orders_data)
            except:
                pass

            # å›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•
            return self.driver.find_elements(
                By.XPATH,
                "//a[contains(@href, 'order.html') or contains(@href, 'order_sn')]",
            )

    def _create_mock_elements(self, orders_data):
        """åˆ›å»ºæ¨¡æ‹Ÿå…ƒç´ å¯¹è±¡"""

        class MockElement:
            def __init__(self, order_sn, order_link):
                self.order_sn = order_sn
                self.order_link = order_link

            def get_attribute(self, attr):
                if attr == "href":
                    return self.order_link
                return None

        return [
            MockElement(order["order_sn"], order["order_link"]) for order in orders_data
        ]


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="æ‹¼å¤šå¤šä¸ªäººè®¢å•çˆ¬å–å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python pdd_order_scraper_optimized.py                    # ä½¿ç”¨é»˜è®¤30å¤©èŒƒå›´
  python pdd_order_scraper_optimized.py -d 7              # åªæ˜¾ç¤º7å¤©å†…çš„è®¢å•
  python pdd_order_scraper_optimized.py --days 90         # æ˜¾ç¤º90å¤©å†…çš„è®¢å•
  python pdd_order_scraper_optimized.py -d 365 --headless # 365å¤©ï¼Œæ— å¤´æ¨¡å¼
        """,
    )

    parser.add_argument(
        "-d",
        "--days",
        type=int,
        default=30,
        help="æ˜¾ç¤ºå¤šå°‘å¤©å†…çš„å†å²è®¢å• (é»˜è®¤: 30å¤©)",
    )

    parser.add_argument(
        "--headless",
        action="store_true",
        help="ä½¿ç”¨æ— å¤´æ¨¡å¼è¿è¡Œæµè§ˆå™¨",
    )

    parser.add_argument(
        "--initial-scrolls",
        type=int,
        default=50,
        help="åˆå§‹PageDownæ»šåŠ¨æ¬¡æ•° (é»˜è®¤: 50)",
    )

    parser.add_argument(
        "--max-scrolls",
        type=int,
        default=100,
        help="PageDownæ»šåŠ¨æœ€å¤§æ€»æ¬¡æ•° (é»˜è®¤: 100)",
    )

    return parser.parse_args()


def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_arguments()

    print("æ‹¼å¤šå¤šè®¢å•çˆ¬å–å·¥å…· v4.3")
    print("=" * 50)
    print("âœ¨ æ–°å¢åŠŸèƒ½:")
    print(f"   - å‘½ä»¤è¡Œå‚æ•°æ§åˆ¶: -d/--days (å½“å‰: {args.days}å¤©)")
    print(
        f"   - æ™ºèƒ½PageDownæ»šåŠ¨ (åˆå§‹{args.initial_scrolls}æ¬¡ï¼Œæœ€å¤§{args.max_scrolls}æ¬¡)"
    )
    print("   - æ ¹æ®è®¢å•å·å‰6ä½åˆ¤æ–­æ—¥æœŸèŒƒå›´")
    print("   - æ”¹è¿›ç¿»é¡µé€»è¾‘ï¼šå…ˆPageDownåˆ°åº•éƒ¨ï¼Œç‚¹å‡»æœ€åä¸€ä¸ªè®¢å•æ£€æŸ¥")
    print()

    # åŠ è½½é…ç½®
    config_file = "pdd_config.json"
    config = {}
    if os.path.exists(config_file):
        try:
            with open(config_file, "r", encoding="utf-8") as f:
                config = json.load(f)
        except:
            config = {}

    # è·å–æ‰‹æœºå·
    phone = os.getenv("PDD_PHONE") or config.get("phone")
    if not phone:
        phone = input("è¯·è¾“å…¥æ‰‹æœºå·: ").strip()
        # ä¿å­˜æ‰‹æœºå·åˆ°é…ç½®
        config["phone"] = phone
        try:
            with open(config_file, "w", encoding="utf-8") as f:
                json.dump(config, f, ensure_ascii=False, indent=2)
            print(f"âœ… æ‰‹æœºå·å·²ä¿å­˜åˆ° {config_file}ï¼Œä¸‹æ¬¡è¿è¡Œå°†è‡ªåŠ¨ä½¿ç”¨")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜æ‰‹æœºå·å¤±è´¥: {e}")

    login_type = os.getenv("PDD_LOGIN_TYPE") or config.get("login_type", "qr")
    if login_type not in ["sms", "qr"]:
        login_type = "qr"

    # åˆå§‹åŒ–çˆ¬è™«ï¼Œä¼ å…¥dayså‚æ•°
    scraper = PinduoduoOrderScraper(headless=args.headless, days=args.days)

    try:
        scraper.start_browser()

        success = scraper.login_via_personal_center(phone, login_type)

        if success:
            print("âœ… ç™»å½•æˆåŠŸï¼")
            print(f"âœ… æ˜¾ç¤ºæ¨¡å¼: {scraper.display_mode}")
            print(f"ğŸ“… è®¢å•æ—¥æœŸèŒƒå›´: {args.days}å¤©å†…")

            # ğŸ” åœ¨å½“å‰é¡µé¢æœç´¢è®¢å•é“¾æ¥ï¼ˆä¸è·³è½¬ï¼‰
            print("\n" + "=" * 60)
            print("ğŸ” å¼€å§‹åœ¨å½“å‰é¡µé¢æœç´¢è®¢å•è·³è½¬é“¾æ¥...")
            print("=" * 60 + "\n")

            found_links, clickable_elements = (
                scraper.search_order_links_on_current_page()
            )

            # è‡ªåŠ¨ç‚¹å‡»"æŸ¥çœ‹å…¨éƒ¨"è¿›å…¥å®Œæ•´è®¢å•åˆ—è¡¨
            print("\nğŸ¯ è‡ªåŠ¨ç‚¹å‡»æŸ¥çœ‹å…¨éƒ¨è¿›å…¥å®Œæ•´è®¢å•åˆ—è¡¨...")

            try:
                # æŸ¥æ‰¾å¹¶ç‚¹å‡»'æŸ¥çœ‹å…¨éƒ¨'å…ƒç´ 
                view_all_elements = scraper.driver.find_elements(
                    By.CSS_SELECTOR, "div.others"
                )
                clicked = False

                for i, elem in enumerate(view_all_elements):
                    text = elem.text.strip()
                    if "æŸ¥çœ‹å…¨éƒ¨" in text:
                        print(
                            f"âœ… æ‰¾åˆ°'æŸ¥çœ‹å…¨éƒ¨'æŒ‰é’®ï¼ˆç¬¬{i + 1}ä¸ªï¼‰ï¼Œç±»å: {elem.get_attribute('class')}"
                        )

                        # æ»šåŠ¨åˆ°å…ƒç´ ä½ç½®
                        scraper.driver.execute_script(
                            "arguments[0].scrollIntoView(true);", elem
                        )
                        time.sleep(1)

                        # ç‚¹å‡»å…ƒç´ 
                        scraper.driver.execute_script("arguments[0].click();", elem)
                        print("âœ… å·²ç‚¹å‡»'æŸ¥çœ‹å…¨éƒ¨'ï¼Œç­‰å¾…é¡µé¢è·³è½¬...")
                        clicked = True
                        break

                if not clicked:
                    print("âŒ æœªæ‰¾åˆ°'æŸ¥çœ‹å…¨éƒ¨'æŒ‰é’®")

                # ç­‰å¾…é¡µé¢è·³è½¬
                time.sleep(3)

                # æ£€æŸ¥é¡µé¢æ˜¯å¦è·³è½¬
                new_url = scraper.driver.current_url
                new_page_source = scraper.driver.page_source

                print(f"ğŸ“ è·³è½¬åURL: {new_url}")

                # ğŸš¨ å¤„ç†å¯èƒ½çš„å¼¹çª—
                try:
                    # ç­‰å¾…ä¸€ä¸‹çœ‹æ˜¯å¦æœ‰å¼¹çª—å‡ºç°
                    time.sleep(2)

                    # å°è¯•å…³é—­å¯èƒ½çš„å¤–éƒ¨æ‰“å¼€æ–‡ä»¶å¼¹çª—
                    # æ–¹æ³•1: æŸ¥æ‰¾å…³é—­æŒ‰é’®
                    close_selectors = [
                        "//*[contains(text(), 'å–æ¶ˆ')]",
                        "//*[contains(text(), 'å…³é—­')]",
                        "//*[contains(text(), 'ç¨å')]",
                        "//*[contains(text(), 'ä¸å†æé†’')]",
                        ".close-btn",
                        ".cancel-btn",
                        "[class*='close']",
                    ]

                    for selector in close_selectors:
                        try:
                            if selector.startswith("//"):
                                elements = scraper.driver.find_elements(
                                    By.XPATH, selector
                                )
                            else:
                                elements = scraper.driver.find_elements(
                                    By.CSS_SELECTOR, selector
                                )

                            for elem in elements:
                                if elem.is_displayed():
                                    elem_text = elem.text.strip()
                                    print(
                                        f"  ğŸ”§ æ‰¾åˆ°å¯èƒ½çš„å¼¹çª—æŒ‰é’®: '{elem_text}' ({selector})"
                                    )
                                    scraper.driver.execute_script(
                                        "arguments[0].click();", elem
                                    )
                                    time.sleep(1)
                                    print("  âœ… å·²ç‚¹å‡»å…³é—­å¼¹çª—")
                                    break
                        except:
                            continue

                except Exception as e:
                    print(f"  âš ï¸ å¤„ç†å¼¹çª—æ—¶å‡ºé”™: {e}")

                # å†æ¬¡ç­‰å¾…é¡µé¢ç¨³å®š
                time.sleep(3)
                new_page_source = scraper.driver.page_source

                # åˆ†æè·³è½¬åçš„é¡µé¢
                if 'class="order-menu"' not in new_page_source:
                    print("âœ… é¡µé¢å·²è·³è½¬ï¼Œä¸å†æ˜¾ç¤ºæ¦‚è§ˆé¡µé¢")
                    scraper.display_mode = "full_orders_list"

                    # ğŸ“¦ æ™ºèƒ½æ»šåŠ¨åŠ è½½å†å²è®¢å•
                    print(f"\nğŸ“¦ å¼€å§‹æ™ºèƒ½åŠ è½½å†å²è®¢å• (èŒƒå›´: {args.days}å¤©å†…)...")

                    # æ™ºèƒ½æ»šåŠ¨ï¼šå…ˆPageDownï¼Œå†æ£€æŸ¥æœ€åä¸€ä¸ªè®¢å•
                    success = scraper.smart_scroll_to_load_orders(
                        initial_scrolls=args.initial_scrolls,
                        max_scrolls=args.max_scrolls,
                    )

                    if success:
                        print("âœ… æˆåŠŸå®Œæˆè®¢å•èŒƒå›´æ£€æŸ¥")
                    else:
                        print("âš ï¸ è®¢å•èŒƒå›´æ£€æŸ¥æœªå®Œæˆ")

                    # ä¿å­˜è·³è½¬åçš„é¡µé¢
                    from datetime import datetime

                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    full_orders_file = f"pdd_full_orders_{timestamp}.html"
                    with open(full_orders_file, "w", encoding="utf-8") as f:
                        f.write(new_page_source)
                    print(f"ğŸ’¾ å®Œæ•´è®¢å•é¡µé¢å·²ä¿å­˜: {full_orders_file}")

                    # åˆ†æå®Œæ•´è®¢å•é¡µé¢
                    print("\nğŸ” åˆ†æå®Œæ•´è®¢å•é¡µé¢...")

                    # æµ‹è¯•è®¢å•é€‰æ‹©å™¨
                    test_selectors = [
                        ".order-item",
                        ".goods-item",
                        "[class*='order']",
                        "div[class*='item']",
                    ]

                    best_selector = None
                    max_elements = 0

                    for selector in test_selectors:
                        try:
                            elements = scraper.driver.find_elements(
                                By.CSS_SELECTOR, selector
                            )
                            if elements:
                                print(f"  {selector}: {len(elements)} ä¸ªå…ƒç´ ")

                                if len(elements) > max_elements:
                                    max_elements = len(elements)
                                    best_selector = selector

                                # æ˜¾ç¤ºå‰2ä¸ªå…ƒç´ çš„é¢„è§ˆ
                                for j, elem in enumerate(elements[:2]):
                                    try:
                                        text = elem.text.strip()
                                        if len(text) > 20:
                                            preview = text[:80].replace("\n", " | ")
                                            print(f"    [{j + 1}] {preview}...")
                                    except:
                                        continue
                        except:
                            continue

                    if best_selector:
                        print(f"\nğŸ¯ å®Œæ•´è®¢å•é¡µé¢åˆ†æå®Œæˆï¼")
                        print(
                            f"ğŸ† æ¨èçš„è®¢å•é€‰æ‹©å™¨: {best_selector} (æ‰¾åˆ° {max_elements} ä¸ªå…ƒç´ )"
                        )
                        print(f"\nğŸ’¡ å¯ä»¥ç”¨è¿™ä¸ªé€‰æ‹©å™¨ä¼˜åŒ–è®¢å•æå–é€»è¾‘")
                    else:
                        print("\nâš ï¸ å®Œæ•´è®¢å•é¡µé¢æœªæ‰¾åˆ°æ˜ç¡®çš„è®¢å•é€‰æ‹©å™¨")
                else:
                    print("âš ï¸ é¡µé¢å¯èƒ½æœªå®Œå…¨è·³è½¬ï¼Œä»æ˜¾ç¤ºæ¦‚è§ˆé¡µé¢")

            except Exception as e:
                print(f"âŒ ç‚¹å‡»'æŸ¥çœ‹å…¨éƒ¨'å¤±è´¥: {e}")

            # è®¾ç½®æ ‡å¿—ï¼Œè¡¨ç¤ºå·²ç»åœ¨è®¢å•ç›¸å…³é¡µé¢
            scraper.is_already_on_orders_page = True

        if scraper.navigate_to_orders():
            max_pages = input("è¯·è¾“å…¥æœ€å¤§é¡µæ•° (é»˜è®¤10): ").strip()
            max_pages = int(max_pages) if max_pages else 10
            orders = scraper.order_processor.scrape_orders(max_pages=max_pages)
            print(f"\nå…±è·å– {len(orders)} ä¸ªè®¢å•")
            scraper.save_orders()
            scraper.order_processor.generate_report()

    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"é”™è¯¯: {e}")
    finally:
        self.close()

    def close(self):
        if self.driver:
            self.driver.quit()


if __name__ == "__main__":
    main()
